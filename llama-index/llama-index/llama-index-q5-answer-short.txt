LlamaIndex uses text splitters (often via a NodeParser) to break documents into Node objects. For example, the TokenTextSplitter is a common splitter that divides text based on token count. In code, TokenTextSplitter (subclass of MetadataAwareTextSplitter) has parameters like chunk_size and chunk_overlap to control the size of each chunk and overlap between chunks​. It splits the input by tokens (default separator is space) and produces text chunks up to chunk_size tokens, overlapping by chunk_overlap tokens if specified​. These chunks become Node objects (with their text and metadata) which the index then stores. Different parsers/splitters exist for specific formats (HTML, JSON, code, etc.), but they all serve to chunk source documents into smaller pieces for indexing.
